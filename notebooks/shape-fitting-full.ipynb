{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da849a4f-0493-4c4f-baa9-be4a8e69e87e",
   "metadata": {},
   "source": [
    "# Fitting shape models - including pose\n",
    "\n",
    "#### Marcel LÃ¼thi, Departement of Mathematics and Computer Science, University of Basel \n",
    "\n",
    "This notebook serves as a template for a more complete fitting project that does a 3D from 2D reconstruction of the vertebra, where the pose is not known. The code in this notebook is structurally correct, but the priors, evaluators and proposals are not tuned and the reconstruction as such are therefore not going to work. Your task is to make it work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325f6c3-c9d9-40dc-9ac0-1f6bcdb379c8",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We begin as usual with importing all the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118fc52e-ead0-4941-9559-953c05f35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mapi\u001b[39m: \u001b[32mJupyterApi\u001b[39m = almond.JupyterApiImpl@2b0799fa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Suppressing excessive output for the jupyter-notebook\n",
    "val api = implicitly[almond.api.JupyterApi]\n",
    "api.silent(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6c8486-c1af-408e-b818-7285a6a3e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// add repositories from which libraries are loaded. \n",
    "import coursierapi.{Credentials, MavenRepository}\n",
    "interp.repositories() ++= Seq(\n",
    "  MavenRepository.of(\"https://oss.sonatype.org/content/repositories/snapshots\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cd74f6-3c9a-4f93-bcd0-65d715d2a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// downloading the libraries\n",
    "import $ivy.`ch.unibas.cs.gravis::scalismo-plot:0.1-SNAPSHOT`\n",
    "import $ivy.`ch.unibas.cs.gravis::scalismo-renderer:0.1-SNAPSHOT`\n",
    "import $ivy.`org.scalanlp::breeze:2.1.0`\n",
    "import $ivy.`org.scalanlp::breeze-natives:2.1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e0b6f0-c950-497c-b692-25044847d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "// imports\n",
    "\n",
    "// scalismo imports\n",
    "import scalismo.io.StatisticalModelIO\n",
    "import scalismo.io.LandmarkIO\n",
    "import scalismo.geometry.*\n",
    "import scalismo.common.*\n",
    "import scalismo.statisticalmodel.*\n",
    "import scalismo.mesh.{TriangleMesh, LineMesh}\n",
    "import scalismo.transformations.*\n",
    "\n",
    "// sampling framework\n",
    "import scalismo.sampling._\n",
    "import scalismo.sampling.proposals._\n",
    "import scalismo.sampling.parameters._\n",
    "import scalismo.sampling.evaluators._\n",
    "import scalismo.sampling.loggers.MHSampleLogger\n",
    "import scalismo.sampling.algorithms.MetropolisHastings\n",
    "\n",
    "\n",
    "// rendering\n",
    "import scalismo.renderer.{ContourRenderer, Renderer, show, PixelImage}\n",
    "import scalismo.color.RGB\n",
    "\n",
    "// plotting\n",
    "import scalismo.plot.data.DataFrame\n",
    "import scalismo.plot.plottarget.PlotTarget.plotTargetJupyter\n",
    "\n",
    "// linear algebra and statistics\n",
    "import breeze.linalg.DenseVector\n",
    "import breeze.linalg.DenseMatrix\n",
    "import breeze.stats.distributions.{Gaussian, MultivariateGaussian}\n",
    "import breeze.stats.distributions.Rand.FixedSeed.randBasis\n",
    "\n",
    "// java helpers\n",
    "import java.io.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57231a01-2782-4d23-a4c1-fa9a9effe119",
   "metadata": {},
   "outputs": [],
   "source": [
    "given rng: scalismo.utils.Random = scalismo.utils.Random(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fda8f-610f-4f86-bbac-78e6b10ba0eb",
   "metadata": {},
   "source": [
    "### Generating simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8dec0-f5f1-4021-b63e-721c6e843d92",
   "metadata": {},
   "source": [
    "The following function generates a contour for the given parameters. Note that it is possible to add a pose transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740c6295-59ff-4e12-99b4-e69ac0c07986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(vertebraModel : PointDistributionModel[_3D, TriangleMesh], \n",
    "             poseTransform : RigidTransformation[_3D], \n",
    "             shapeCoefficients : DenseVector[Double], \n",
    "             sensorDistance : Int, \n",
    "             sourceLocation : Point[_3D], \n",
    "             noiseSigma : Double) : LineMesh[_2D] = \n",
    "    \n",
    "    // sample from the prior    \n",
    "    val sample = vertebraModel.instance(shapeCoefficients).transform(poseTransform)\n",
    "\n",
    "    // project the sampled shape to get the contour\n",
    "    val sampledContour = ContourRenderer.projectMeshContours(sample, sensorDistance, sourceLocation)\n",
    "    \n",
    "    if noiseSigma > 1e-5 then     \n",
    "        // add Gaussian noise to each point  \n",
    "        val noiseTransform = Transformation2D( (point : Point[_2D]) => \n",
    "            val pointVec = DenseVector(point.x, point.y)\n",
    "            val noisyPoint = MultivariateGaussian(pointVec, DenseMatrix.eye[Double](2)* noiseSigma).draw()\n",
    "\n",
    "            Point2D(noisyPoint(0), noisyPoint(1))\n",
    "        )                 \n",
    "        sampledContour.transform(noiseTransform)\n",
    "    else sampledContour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519ed2c-81b1-4429-8495-2880138910a1",
   "metadata": {},
   "source": [
    "Generate a target contour to be fitted. By adjusting the pose parameters, you can make the problem more or less difficult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899a4806-ee4c-4cb5-9529-fc8ec11362d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val vertebraModel = StatisticalModelIO.readStatisticalTriangleMeshModel3D(File(\"./data/vertebra-model.h5\")).get\n",
    "val rot = Rotation3D(0.1, 0.0, 0.0, Point3D(0, 0, 0))\n",
    "val translation = Translation3D(EuclideanVector3D(10, 5, 3))\n",
    "val poseTransform = TranslationAfterRotation3D(translation, rot)\n",
    "\n",
    "val coeffs = DenseVector.zeros[Double](vertebraModel.rank)\n",
    "coeffs(0) = -3\n",
    "coeffs(1) = 1.0\n",
    "coeffs(2) = 1.5\n",
    "val sensorDistance = 400\n",
    "val sourceLocation = Point3D(0, 0, 100)\n",
    "val noiseSigma : Double = 1\n",
    "\n",
    "val targetContour = generate(vertebraModel, poseTransform, coeffs, sensorDistance, sourceLocation, noiseSigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb54e2f-59a8-445b-abd5-9581c0b1143e",
   "metadata": {},
   "source": [
    "It looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9db155-8184-401c-9c70-3894e451eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ContourRenderer.renderMeshContour(targetContour, 1000, 1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2764ba-f855-47bd-b269-bd4a94b77196",
   "metadata": {},
   "source": [
    "### Setting up the markov chain\n",
    "\n",
    "We can now set up the Markov-Chain to sample from the posterior, exactly as we did it for the regression example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e2f9b-a428-4ad9-a02f-c62ed073a25f",
   "metadata": {},
   "source": [
    "### Parameter vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1fe47-fd12-4d06-adf2-71864c83936a",
   "metadata": {},
   "source": [
    "In contrast to the previous notebook, we use not only the class `ShapeParameter`  to represent our parameters, but also pose parameters. The combo is already defined in Scalismo and is called `PoseAndShapeParameters`. The code below should make it clear how it it used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451cdd9-c23a-4658-b6e4-fe312fc5e446",
   "metadata": {},
   "source": [
    "#### Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318820a-2c1c-446a-809a-0ce790856afa",
   "metadata": {},
   "source": [
    "We start by defining the priors for shape, translation and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7810653-93ea-4101-8f0f-355b4b3dce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Prior over the shape parameters.  \n",
    "case class ShapePriorEvaluator(model: PointDistributionModel[_3D, TriangleMesh])\n",
    "      extends MHDistributionEvaluator[PoseAndShapeParameters] {\n",
    "          \n",
    "    val shapeParameterPrior = MultivariateGaussian(DenseVector.zeros[Double](model.rank), DenseMatrix.eye[Double](model.rank))\n",
    "\n",
    "    override def logValue(sample: MHSample[PoseAndShapeParameters]): Double = {\n",
    "        shapeParameterPrior.logPdf(sample.parameters.shapeParameters.coefficients) \n",
    "    }\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568b6a73-6a79-4a09-bee1-4e8682e3ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Prior over the shape parameters.  \n",
    "object TranslationPriorEvaluator  extends MHDistributionEvaluator[PoseAndShapeParameters] {\n",
    "          \n",
    "    val translationPriorParameterPrior = MultivariateGaussian(DenseVector.zeros[Double](3), DenseMatrix.eye[Double](3) * 3000.0)\n",
    "\n",
    "    override def logValue(sample: MHSample[PoseAndShapeParameters]): Double = {\n",
    "        translationPriorParameterPrior.logPdf(sample.parameters.translationParameters.translationVector.toBreezeVector) \n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf95939-40fd-4a66-bc03-582c72cb3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Prior over the shape parameters.  \n",
    "object RotationPriorEvaluator extends MHDistributionEvaluator[PoseAndShapeParameters] {\n",
    "          \n",
    "    val rotationPhiPrior = breeze.stats.distributions.Uniform(-2 * 3.141, 2 * 3.141)\n",
    "    val rotationPsiPrior = breeze.stats.distributions.Uniform(-2 * 3.141, 2 * 3.141)\n",
    "    val rotationThetaPrior = breeze.stats.distributions.Uniform(-2 * 3.141, 2 * 3.141)\n",
    "    \n",
    "\n",
    "    override def logValue(sample: MHSample[PoseAndShapeParameters]): Double = {\n",
    "        val (phi, psi, theta) = sample.parameters.rotationParameters.angles\n",
    "        rotationPhiPrior.logPdf(phi) + rotationPsiPrior.logPdf(psi) + rotationThetaPrior.logPdf(theta) \n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be134e-a876-4e2d-855d-6ae936977645",
   "metadata": {},
   "source": [
    "The contour evaluator is similar to the one in the previous notebook. There are two important differences:\n",
    "\n",
    "- It applies a rigid transformation to the shape before generating the contour\n",
    "- The distance between the genrated contour and the target contour is computed from the target contour. This makes it possible to work with target contours that are only partially given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3453d353-695d-4a6e-b774-d26ad055a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Likelihood\n",
    "case class ContourEvaluator(\n",
    "        model: PointDistributionModel[_3D, TriangleMesh],\n",
    "        targetContour: LineMesh[_2D], \n",
    "        sensorDistance : Int, \n",
    "        sourceLocation : Point[_3D], \n",
    "        noiseSigma : Double\n",
    "    ) extends MHDistributionEvaluator[PoseAndShapeParameters]:\n",
    "\n",
    "    def pointToBreezeVector(p : Point[_2D]) : DenseVector[Double] = \n",
    "        DenseVector[Double](p.x, p.y)\n",
    "    \n",
    "\n",
    "    override def logValue(sample: MHSample[PoseAndShapeParameters]): Double = \n",
    "        val poseTransformation = ContourEvaluator.transformFromPoseParameters(sample.parameters.rotationParameters, Point3D(0, 0, 0), sample.parameters.translationParameters)\n",
    "        val modelInstance = model.instance(sample.parameters.shapeParameters.coefficients).transform(poseTransformation)\n",
    "        val sampledContour = ContourRenderer.projectMeshContours(modelInstance, sensorDistance, sourceLocation)                \n",
    "    \n",
    "\n",
    "        val likelihoods = for contourPoint <- targetContour.pointSet.points yield            \n",
    "            val likelihoodDist = MultivariateGaussian(pointToBreezeVector(contourPoint), DenseMatrix.eye[Double](2) * noiseSigma)            \n",
    "            val closestSamplePoint = sampledContour.pointSet.findClosestPoint(contourPoint).point            \n",
    "            likelihoodDist.logPdf(pointToBreezeVector(closestSamplePoint))\n",
    "        likelihoods.sum    \n",
    "\n",
    "object ContourEvaluator:\n",
    "    // defines a rigid transformation for the given pose parameters. \n",
    "    def transformFromPoseParameters(rotationParameters : RotationParameters, rotationCenter : Point[_3D], translationParameters : TranslationParameters) : RigidTransformation[_3D] = \n",
    "\n",
    "        val (phi, psi, theta) = rotationParameters.angles\n",
    "        val rot = Rotation3D(phi, psi, theta, rotationCenter)\n",
    "        val translation = Translation3D(translationParameters.translationVector)\n",
    "        TranslationAfterRotation(translation, rot)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f198f8-e4b1-45db-86ee-3d57d2dbb2f2",
   "metadata": {},
   "source": [
    "The posterior is defined as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02aa3f3-9487-44cf-bb44-b9e3ba2a812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val likelihoodEvaluator = ContourEvaluator(vertebraModel, targetContour, sensorDistance, sourceLocation, noiseSigma).cached\n",
    "val priorEvaluator = ProductEvaluator(TranslationPriorEvaluator.cached, ShapePriorEvaluator(vertebraModel).cached, RotationPriorEvaluator.cached)\n",
    "val posteriorEvaluator = ProductEvaluator(likelihoodEvaluator, priorEvaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1bd89-5784-4206-b55e-480a07c3e50f",
   "metadata": {},
   "source": [
    "#### Proposals\n",
    "\n",
    "Next we define the proposals for the Metropolis-Hastings algorithm. As we are dealing with more parameters, we need more sophisticated proposals. See [Tutorial 15](https://scalismo.org/docs/Tutorials/tutorial15) of the Scalismo documentation for details on how to set up such proposals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba51715a-eed8-481e-8553-466e84b98d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "val identTranslationProposal = MHIdentityProposal.forType[TranslationParameters]\n",
    "val identRotationProposal = MHIdentityProposal.forType[RotationParameters]\n",
    "val identShapeProposal = MHIdentityProposal.forType[ShapeParameters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf69bae3-693e-492d-90c4-6bdfd4f8cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "val shapeProposal =\n",
    "    GaussianRandomWalkProposal(0.05, \"shape\")\n",
    "      .forType[ShapeParameters]\n",
    "\n",
    "val shapeOnlyProposal = MHProductProposal(\n",
    "    identTranslationProposal, \n",
    "    identRotationProposal, \n",
    "    shapeProposal\n",
    ").forType[PoseAndShapeParameters]\n",
    "  .relabel(\"shape-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d91048b-7bca-45fa-94ae-0770ddc77189",
   "metadata": {},
   "outputs": [],
   "source": [
    "val translationProposal = MHProductProposal(\n",
    "    GaussianRandomWalkProposal(0.1, \"tx\").forType[Double],\n",
    "    GaussianRandomWalkProposal(0.1, \"ty\").forType[Double],\n",
    "    GaussianRandomWalkProposal(0.1, \"tz\").forType[Double]\n",
    "  ).forType[TranslationParameters]\n",
    "    .relabel(\"translation-only\")\n",
    "\n",
    "val translationOnlyProposal = MHProductProposal(\n",
    "    translationProposal, \n",
    "    identRotationProposal,\n",
    "    identShapeProposal\n",
    ").forType[PoseAndShapeParameters]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea80f70-7fc8-4d4a-b47c-da69146b0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "val rotationProposal = MHProductProposal(\n",
    "    GaussianRandomWalkProposal(0.01, \"rx\").forType[Double],\n",
    "    GaussianRandomWalkProposal(0.01, \"ry\").forType[Double],\n",
    "    GaussianRandomWalkProposal(0.01, \"rz\").forType[Double]\n",
    "  ).forType[RotationParameters].relabel(\"rotation-only\")\n",
    "\n",
    "val rotationOnlyProposal = MHProductProposal(\n",
    "    identTranslationProposal, \n",
    "    rotationProposal,\n",
    "    identShapeProposal\n",
    ").forType[PoseAndShapeParameters]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d68f6a-8d69-4d4c-af40-9c6d885510e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  val mixturePoseAndShapeProposal = MHMixtureProposal(\n",
    "    (0.5, shapeOnlyProposal),\n",
    "    (0.3, translationOnlyProposal), \n",
    "    (0.2, rotationOnlyProposal)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a6aaf-2fa7-41d1-ac7f-81990fd70247",
   "metadata": {},
   "source": [
    "#### Putting it together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df4a78-fea3-471a-bf0f-99772eca2352",
   "metadata": {},
   "source": [
    "We can now put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9b6cd68-661b-4c0b-9bdd-279030667ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val logger = MHSampleLogger[PoseAndShapeParameters]()\n",
    "val chain = MetropolisHastings(mixturePoseAndShapeProposal, posteriorEvaluator)\n",
    "\n",
    "val initialParameters = PoseAndShapeParameters(\n",
    "    TranslationParameters(EuclideanVector3D(0,0,0)), \n",
    "    RotationParameters(0.0, 0.0, 0.0), \n",
    "    ShapeParameters(DenseVector.zeros[Double](vertebraModel.rank))\n",
    ")\n",
    "val mhIterator = chain.iterator(MHSample(initialParameters, \"inital\"), logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e7b17-1af5-48ea-92aa-672a786be00b",
   "metadata": {},
   "source": [
    "Let's draw some samples from the posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafb4d3-4aa8-459a-a88f-6e97e97456d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val samples = mhIterator.drop(1000).take(2000).toIndexedSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc75d2-a98e-4bed-a31c-8ed3346dffbd",
   "metadata": {},
   "source": [
    "The most likely reconstruction is given by the sample with the highest posterior value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21478b25-3456-42ce-987e-09541fc56963",
   "metadata": {},
   "outputs": [],
   "source": [
    "val bestSample = samples.maxBy(posteriorEvaluator.logValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6f9ba-3d97-480b-90bd-db8f0704d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(bestSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9af10e-5284-432b-860f-c6fe726a60ed",
   "metadata": {},
   "source": [
    "This does not mean, however, that fitting did not work. Let's visualize the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823361b-b683-4723-9954-986ef1fd8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val bestMesh = vertebraModel.instance(bestSample.parameters.shapeParameters.coefficients)\n",
    "    .transform(ContourEvaluator.transformFromPoseParameters(bestSample.parameters.rotationParameters, Point3D(0,0,0), bestSample.parameters.translationParameters))\n",
    "val bestConour = ContourRenderer.projectMeshContours(bestMesh, sensorDistance, sourceLocation)\n",
    "ContourRenderer.renderMeshContours(Seq((bestConour, RGB(1.0, 0, 0)), (targetContour, RGB(0, 0, 1.0))), 1000, 1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5281000-4420-4d18-a69b-22bb867eb734",
   "metadata": {},
   "source": [
    "As we see, the two contours are really close together. Let's see how the reconstruction looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f73db8-7203-446b-b890-419a00d688fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(mesh : TriangleMesh[_3D]) : Unit = \n",
    "    Renderer.renderMesh(mesh, RGB.White, Point3D(0, 0, 250), 256, 256).show()\n",
    "render(bestMesh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f65036-06a5-43cc-9682-ee279f2780b1",
   "metadata": {},
   "source": [
    "Now we show some more contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd12a7-6801-4f04-b45b-2b371172609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val numContours = 30\n",
    "val someContours = for sample <- samples.grouped(samples.length / numContours).map(_.head).toIndexedSeq yield \n",
    "    val mesh = vertebraModel.instance(sample.parameters.shapeParameters.coefficients)\n",
    "    .transform(ContourEvaluator.transformFromPoseParameters(sample.parameters.rotationParameters, Point3D(0,0,0), sample.parameters.translationParameters))\n",
    "    ContourRenderer.projectMeshContours(mesh, sensorDistance, sourceLocation)\n",
    "\n",
    "val coloredContours = (targetContour, RGB(0, 0, 1.0)) +: someContours.map(c => (c, RGB(1.0, 0, 0)))\n",
    "ContourRenderer.renderMeshContours(coloredContours, 1000, 1000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7a876-9c0f-4290-a191-646ba3bb8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = DataFrame(Seq(\n",
    "    DataFrame.Column.ofContinuous(samples.map(s => s.parameters.shapeParameters.coefficients(0)), \"coeff-0\"), \n",
    "    DataFrame.Column.ofContinuous(samples.map(s => s.parameters.shapeParameters.coefficients(1)), \"coeff-1\"), \n",
    "    DataFrame.Column.ofContinuous(samples.map(s => s.parameters.shapeParameters.coefficients(2)), \"coeff-2\"), \n",
    "    )\n",
    ")\n",
    "\n",
    "df.plot.pairPlot(Seq(\"coeff-0\", \"coeff-1\", \"coeff-2\"), title = \"Pairs\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb43b7-142e-4f08-8851-7dccda036f46",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "* Make more complicated pose changes. Does it still work?\n",
    "* How do the priors affect the result?\n",
    "* Print the acceptance ratios for your proposals. Which work, which don't? How con you tune them?\n",
    "* Try to fit the contour drawn in the image `spine-contour-handdrawn`, which you find in the folder `images`. You can load the image and extract the contour with the code below. \n",
    "* Draw your own contour using an arbitrary drawing problen on an x-ray of the L1 vertebra you find on the internet. Make sure you draw the contour in Black. You can extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b145ec7-8b39-4f45-a37b-b5ae330b1e6f",
   "metadata": {},
   "source": [
    "### Useful snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09446c51-f13e-4a91-bb2a-0949f17ab7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "// extract the target contour from the image.\n",
    "\n",
    "val bufferedImage = javax.imageio.ImageIO.read(new java.io.File(\"./data/spine-contour-handdrawn.png\"))\n",
    "val image  = PixelImage.fromBufferedImage(bufferedImage)\n",
    "val targetContourNotCentered = Contour.fromImage(image).get\n",
    "val centerTransform = Translation2D(Point2D(0, 0) - targetContourNotCentered.pointSet.centerOfMass)\n",
    "val targetContour = targetContourNotCentered.transform(centerTransform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
